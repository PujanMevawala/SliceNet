{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10410954,"sourceType":"datasetVersion","datasetId":6451942}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.preprocessing import MinMaxScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport flwr as fl\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Load dataset\ndata = pd.read_csv('/kaggle/input/deep-slice/deepslice_data.csv')\n\n# Encoding categorical variables\nencoders = {}\nfor col in ['Use Case', 'Technology Supported', 'Day', 'GBR', 'slice Type']:\n    encoders[col] = LabelEncoder()\n    data[col] = encoders[col].fit_transform(data[col])\n\n# Separate features and target\nX = data.drop(columns=['slice Type'])\ny = data['slice Type']\n\n# Normalize features\nscaler = MinMaxScaler()\nX_normalized = scaler.fit_transform(X)\n\n# Add Gaussian noise\nX_noisy = X_normalized + 0.27 * np.random.normal(loc=0.0, scale=1.0, size=X_normalized.shape)\n\n# Reshape for RNN\nX_reshaped = X_noisy.reshape(X_noisy.shape[0], 1, X_noisy.shape[1])\n\n# Convert to PyTorch tensors\nX_tensor = torch.tensor(X_reshaped, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.long)\n\n# Split dataset equally for 3 clients\nnum_samples = len(y) // 3\nindices = np.arange(len(y))\nnp.random.shuffle(indices)\nclient_datasets = [indices[i * num_samples:(i + 1) * num_samples] for i in range(3)]\n\n# Define Custom PyTorch Dataset\nclass CustomDataset(Dataset):\n    def __init__(self, X, y):\n        self.X = X\n        self.y = y\n\n    def __len__(self):\n        return len(self.y)\n\n    def __getitem__(self, idx):\n        return self.X[idx], self.y[idx]\n\n# Create client datasets\nclient_data = [CustomDataset(X_tensor[idx], y_tensor[idx]) for idx in client_datasets]\n\n# Define RNN Model\nclass RNNModel(nn.Module):\n    def __init__(self, input_dim, num_classes):\n        super(RNNModel, self).__init__()\n        self.rnn = nn.RNN(input_dim, 64, batch_first=True, nonlinearity='relu')\n        self.lstm = nn.LSTM(64, 64, batch_first=True)\n        self.fc = nn.Linear(64, num_classes)\n\n    def forward(self, x):\n        x, _ = self.rnn(x)\n        x, _ = self.lstm(x)\n        x = self.fc(x[:, -1, :])\n        return x\n\n# Flower Client Class\nclass FlowerClient(fl.client.NumPyClient):\n    def __init__(self, model, train_loader, test_loader):\n        self.model = model\n        self.train_loader = train_loader\n        self.test_loader = test_loader\n        self.criterion = nn.CrossEntropyLoss()\n        self.optimizer = optim.AdamW(self.model.parameters())\n\n    def get_parameters(self, config=None):\n        return [val.cpu().numpy() for val in self.model.state_dict().values()]\n\n    def set_parameters(self, parameters):\n        parameters_dict = zip(self.model.state_dict().keys(), parameters)\n        state_dict = {k: torch.tensor(v) for k, v in parameters_dict}\n        self.model.load_state_dict(state_dict)\n\n    def train(self):\n        self.model.train()\n        for epoch in range(10):  # Increased epochs to 10\n            epoch_loss = 0.0\n            for X_batch, y_batch in self.train_loader:\n                self.optimizer.zero_grad()\n                outputs = self.model(X_batch)\n                loss = self.criterion(outputs, y_batch)\n                loss.backward()\n                self.optimizer.step()\n                epoch_loss += loss.item()\n            epoch_loss /= len(self.train_loader)\n            print(f\"Epoch {epoch + 1}: Train Loss = {epoch_loss:.4f}\")\n\n    def test(self):\n        self.model.eval()\n        all_targets = []\n        all_predictions = []\n        total_loss = 0.0\n        with torch.no_grad():\n            for X_batch, y_batch in self.test_loader:\n                outputs = self.model(X_batch)\n                loss = self.criterion(outputs, y_batch)\n                total_loss += loss.item()\n                _, predicted = torch.max(outputs, 1)\n                all_targets.extend(y_batch.cpu().numpy())\n                all_predictions.extend(predicted.cpu().numpy())\n\n        accuracy = accuracy_score(all_targets, all_predictions)\n        precision = precision_score(all_targets, all_predictions, average='macro', zero_division=0)\n        recall = recall_score(all_targets, all_predictions, average='macro', zero_division=0)\n        f1 = f1_score(all_targets, all_predictions, average='macro', zero_division=0)\n        avg_loss = total_loss / len(self.test_loader)\n\n        return avg_loss, accuracy, precision, recall, f1\n\n    def evaluate(self, parameters, config):\n        self.set_parameters(parameters)\n        loss, accuracy, precision, recall, f1 = self.test()\n        print(f\"Client {self.test_loader.dataset.X.shape[0]} Evaluation - Loss: {loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n        return float(loss), len(self.test_loader.dataset), {\n            \"accuracy\": float(accuracy),\n            \"precision\": float(precision),\n            \"recall\": float(recall),\n            \"f1\": float(f1),\n        }\n\n    def fit(self, parameters, config):\n        self.set_parameters(parameters)\n        self.train()\n        return self.get_parameters(), len(self.train_loader.dataset), {}\n\n# Function to create clients\ndef get_client_fn(cid: str) -> fl.client.Client:\n    train_loader = DataLoader(client_data[int(cid)], batch_size=32, shuffle=True)\n    test_loader = DataLoader(client_data[int(cid)], batch_size=32, shuffle=False)\n    model = RNNModel(input_dim=X_tensor.shape[2], num_classes=len(y.unique()))\n    numpy_client = FlowerClient(model, train_loader, test_loader)\n    return numpy_client.to_client()\n\n# Custom evaluation function to print aggregated model metrics\ndef evaluate_aggregated_model(server_round, parameters, config):\n    model = RNNModel(input_dim=X_tensor.shape[2], num_classes=len(y.unique()))\n    params_dict = zip(model.state_dict().keys(), parameters)\n    state_dict = {k: torch.tensor(v) for k, v in params_dict}\n    model.load_state_dict(state_dict)\n    \n    test_loader = DataLoader(CustomDataset(X_tensor, y_tensor), batch_size=32, shuffle=False)\n    criterion = nn.CrossEntropyLoss()\n    \n    model.eval()\n    all_targets = []\n    all_predictions = []\n    total_loss = 0.0\n    with torch.no_grad():\n        for X_batch, y_batch in test_loader:\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            total_loss += loss.item()\n            _, predicted = torch.max(outputs, 1)\n            all_targets.extend(y_batch.cpu().numpy())\n            all_predictions.extend(predicted.cpu().numpy())\n\n    accuracy = accuracy_score(all_targets, all_predictions)\n    precision = precision_score(all_targets, all_predictions, average='macro', zero_division=0)\n    recall = recall_score(all_targets, all_predictions, average='macro', zero_division=0)\n    f1 = f1_score(all_targets, all_predictions, average='macro', zero_division=0)\n    avg_loss = total_loss / len(test_loader)\n\n    print(f\"Aggregated Model Evaluation - Round {server_round}: Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1: {f1:.4f}\")\n    return avg_loss, {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n\n# Federated Learning Strategy with custom evaluate function\nstrategy = fl.server.strategy.FedAvg(\n    evaluate_fn=evaluate_aggregated_model  # Add the custom evaluation function\n)\n\n# Start Flower Simulation\nfl.simulation.start_simulation(\n    client_fn=get_client_fn,\n    num_clients=3,\n    config=fl.server.ServerConfig(num_rounds=5),\n    strategy=strategy\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T10:21:44.814798Z","iopub.execute_input":"2025-02-07T10:21:44.815084Z","iopub.status.idle":"2025-02-07T10:24:43.064023Z","shell.execute_reply.started":"2025-02-07T10:21:44.815062Z","shell.execute_reply":"2025-02-07T10:24:43.063073Z"}},"outputs":[{"name":"stderr","text":"\u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: flwr.simulation.start_simulation() is deprecated.\n\tInstead, use the `flwr run` CLI command to start a local simulation in your Flower app, as shown for example below:\n\n\t\t$ flwr new  # Create a new Flower app from a template\n\n\t\t$ flwr run  # Run the Flower app in Simulation Mode\n\n\tUsing `start_simulation()` is deprecated.\n\n            This is a deprecated feature. It will be removed\n            entirely in future versions of Flower.\n        \n\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=5, no round_timeout\n2025-02-07 10:21:48,261\tINFO worker.py:1752 -- Started a local Ray instance.\n\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'node:172.19.2.2': 1.0, 'node:__internal_head__': 1.0, 'memory': 18043713947.0, 'accelerator_type:T4': 1.0, 'CPU': 4.0, 'object_store_memory': 9021856972.0, 'GPU': 2.0}\n\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n\u001b[92mINFO \u001b[0m:      No `client_resources` specified. Using minimal resources for clients.\n\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0.0}\n\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 4 actors\n\u001b[92mINFO \u001b[0m:      [INIT]\n\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n\u001b[36m(pid=1866)\u001b[0m 2025-02-07 10:21:51.463461: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n\u001b[36m(pid=1866)\u001b[0m 2025-02-07 10:21:51.506824: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n\u001b[36m(pid=1866)\u001b[0m 2025-02-07 10:21:51.518898: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             entirely in future versions of Flower.\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m         \n\u001b[36m(pid=1864)\u001b[0m 2025-02-07 10:21:51.658953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(pid=1864)\u001b[0m 2025-02-07 10:21:51.697960: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[36m(pid=1864)\u001b[0m 2025-02-07 10:21:51.709923: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\u001b[32m [repeated 3x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n\u001b[92mINFO \u001b[0m:      Starting evaluation of initial global parameters\n\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 1.1445508008669938, {'accuracy': 0.2288378425443665, 'precision': 0.08289723412713954, 'recall': 0.32591540404040403, 'f1': 0.1304082033134367}\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 1]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 0: Loss: 1.1446, Accuracy: 0.2288, Precision: 0.0829, Recall: 0.3259, F1: 0.1304\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             entirely in future versions of Flower.\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m         \n\u001b[36m(ClientAppActor pid=1864)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m         \u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m             entirely in future versions of Flower.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 1: Train Loss = 0.2198\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1865)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             entirely in future versions of Flower.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 2: Train Loss = 0.1009\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 4: Train Loss = 0.0838\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 7: Train Loss = 0.0758\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 9: Train Loss = 0.0746\u001b[32m [repeated 6x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.07006349834901104, {'accuracy': 0.9750977567400699, 'precision': 0.9702099596306857, 'recall': 0.968864436963376, 'f1': 0.9693834500315214}, 32.79408199100021)\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 1: Loss: 0.0701, Accuracy: 0.9751, Precision: 0.9702, Recall: 0.9689, F1: 0.9694\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m         \u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             entirely in future versions of Flower.\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             This is a deprecated feature. It will be removed\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             entirely in future versions of Flower.\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n\u001b[93mWARNING \u001b[0m:   No evaluate_metrics_aggregation_fn provided\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 2]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1864)\u001b[0m Client 21055 Evaluation - Loss: 0.0709, Accuracy: 0.9741, Precision: 0.9691, Recall: 0.9672, F1: 0.9680\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Epoch 10: Train Loss = 0.0660\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Client 21055 Evaluation - Loss: 0.0729, Accuracy: 0.9748, Precision: 0.9697, Recall: 0.9687, F1: 0.9691\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 3: Train Loss = 0.0656\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Epoch 4: Train Loss = 0.0712\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Epoch 7: Train Loss = 0.0696\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 8: Train Loss = 0.0667\u001b[32m [repeated 7x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.06411021255557037, {'accuracy': 0.9766650307913942, 'precision': 0.9710032293758516, 'recall': 0.9717278781885431, 'f1': 0.9713599021259088}, 64.67867904200011)\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 2: Loss: 0.0641, Accuracy: 0.9767, Precision: 0.9710, Recall: 0.9717, F1: 0.9714\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1864)\u001b[0m         \u001b[32m [repeated 12x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 3]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1864)\u001b[0m Client 21055 Evaluation - Loss: 0.0597, Accuracy: 0.9786, Precision: 0.9734, Recall: 0.9746, F1: 0.9740\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 10: Train Loss = 0.0665\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Client 21055 Evaluation - Loss: 0.0673, Accuracy: 0.9754, Precision: 0.9691, Recall: 0.9699, F1: 0.9695\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 3: Train Loss = 0.0690\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 6: Train Loss = 0.0676\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 9: Train Loss = 0.0654\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Epoch 8: Train Loss = 0.0611\u001b[32m [repeated 6x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.06221808410385321, {'accuracy': 0.9774565833425681, 'precision': 0.9716140816221941, 'recall': 0.9732340020867024, 'f1': 0.9724173080414739}, 96.48799875899999)\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 3: Loss: 0.0622, Accuracy: 0.9775, Precision: 0.9716, Recall: 0.9732, F1: 0.9724\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m         \u001b[32m [repeated 12x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 4]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m Client 21055 Evaluation - Loss: 0.0588, Accuracy: 0.9789, Precision: 0.9735, Recall: 0.9755, F1: 0.9745\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 10: Train Loss = 0.0641\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Client 21055 Evaluation - Loss: 0.0651, Accuracy: 0.9765, Precision: 0.9704, Recall: 0.9719, F1: 0.9711\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 3: Train Loss = 0.0646\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 6: Train Loss = 0.0643\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m Epoch 6: Train Loss = 0.0658\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 8: Train Loss = 0.0589\u001b[32m [repeated 7x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      fit progress: (4, 0.06240133009181528, {'accuracy': 0.9771874554751689, 'precision': 0.9737520527936688, 'recall': 0.9705149008667157, 'f1': 0.9721113667862964}, 128.97083256500014)\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 4: Loss: 0.0624, Accuracy: 0.9772, Precision: 0.9738, Recall: 0.9705, F1: 0.9721\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1865)\u001b[0m         \u001b[32m [repeated 12x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1865)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [ROUND 5]\n\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1865)\u001b[0m Client 21055 Evaluation - Loss: 0.0592, Accuracy: 0.9782, Precision: 0.9753, Recall: 0.9723, F1: 0.9738\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 10: Train Loss = 0.0590\u001b[32m [repeated 4x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Client 21055 Evaluation - Loss: 0.0630, Accuracy: 0.9766, Precision: 0.9731, Recall: 0.9694, F1: 0.9712\u001b[32m [repeated 2x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 2: Train Loss = 0.0602\u001b[32m [repeated 5x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 5: Train Loss = 0.0585\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1864)\u001b[0m Epoch 8: Train Loss = 0.0576\u001b[32m [repeated 7x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 8: Train Loss = 0.0615\u001b[32m [repeated 7x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      fit progress: (5, 0.06114064356780603, {'accuracy': 0.9778206975161081, 'precision': 0.9738072829054154, 'recall': 0.9719091894956504, 'f1': 0.9728450752164716}, 161.11266567000007)\n\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n","output_type":"stream"},{"name":"stdout","text":"Aggregated Model Evaluation - Round 5: Loss: 0.0611, Accuracy: 0.9778, Precision: 0.9738, Recall: 0.9719, F1: 0.9728\n","output_type":"stream"},{"name":"stderr","text":"\u001b[36m(ClientAppActor pid=1866)\u001b[0m         \u001b[32m [repeated 12x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m \u001b[93mWARNING \u001b[0m:   DEPRECATED FEATURE: `client_fn` now expects a signature `def client_fn(context: Context)`.The provided `client_fn` has signature: {'cid': <Parameter \"cid: str\">}. You can import the `Context` like this: `from flwr.common import Context`\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             This is a deprecated feature. It will be removed\u001b[32m [repeated 6x across cluster]\u001b[0m\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m             entirely in future versions of Flower.\u001b[32m [repeated 6x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1864)\u001b[0m Client 21055 Evaluation - Loss: 0.0617, Accuracy: 0.9773, Precision: 0.9735, Recall: 0.9709, F1: 0.9722\n\u001b[36m(ClientAppActor pid=1866)\u001b[0m Epoch 10: Train Loss = 0.0618\u001b[32m [repeated 4x across cluster]\u001b[0m\n","output_type":"stream"},{"name":"stderr","text":"\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n\u001b[92mINFO \u001b[0m:      \n\u001b[92mINFO \u001b[0m:      [SUMMARY]\n\u001b[92mINFO \u001b[0m:      Run finished 5 round(s) in 162.18s\n\u001b[92mINFO \u001b[0m:      \tHistory (loss, distributed):\n\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.07006687837100392\n\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.06411206122838563\n\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.06221993791814982\n\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.06240453636389331\n\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.06114359529982764\n\u001b[92mINFO \u001b[0m:      \tHistory (loss, centralized):\n\u001b[92mINFO \u001b[0m:      \t\tround 0: 1.1445508008669938\n\u001b[92mINFO \u001b[0m:      \t\tround 1: 0.07006349834901104\n\u001b[92mINFO \u001b[0m:      \t\tround 2: 0.06411021255557037\n\u001b[92mINFO \u001b[0m:      \t\tround 3: 0.06221808410385321\n\u001b[92mINFO \u001b[0m:      \t\tround 4: 0.06240133009181528\n\u001b[92mINFO \u001b[0m:      \t\tround 5: 0.06114064356780603\n\u001b[92mINFO \u001b[0m:      \tHistory (metrics, centralized):\n\u001b[92mINFO \u001b[0m:      \t{'accuracy': [(0, 0.2288378425443665),\n\u001b[92mINFO \u001b[0m:      \t              (1, 0.9750977567400699),\n\u001b[92mINFO \u001b[0m:      \t              (2, 0.9766650307913942),\n\u001b[92mINFO \u001b[0m:      \t              (3, 0.9774565833425681),\n\u001b[92mINFO \u001b[0m:      \t              (4, 0.9771874554751689),\n\u001b[92mINFO \u001b[0m:      \t              (5, 0.9778206975161081)],\n\u001b[92mINFO \u001b[0m:      \t 'f1': [(0, 0.1304082033134367),\n\u001b[92mINFO \u001b[0m:      \t        (1, 0.9693834500315214),\n\u001b[92mINFO \u001b[0m:      \t        (2, 0.9713599021259088),\n\u001b[92mINFO \u001b[0m:      \t        (3, 0.9724173080414739),\n\u001b[92mINFO \u001b[0m:      \t        (4, 0.9721113667862964),\n\u001b[92mINFO \u001b[0m:      \t        (5, 0.9728450752164716)],\n\u001b[92mINFO \u001b[0m:      \t 'precision': [(0, 0.08289723412713954),\n\u001b[92mINFO \u001b[0m:      \t               (1, 0.9702099596306857),\n\u001b[92mINFO \u001b[0m:      \t               (2, 0.9710032293758516),\n\u001b[92mINFO \u001b[0m:      \t               (3, 0.9716140816221941),\n\u001b[92mINFO \u001b[0m:      \t               (4, 0.9737520527936688),\n\u001b[92mINFO \u001b[0m:      \t               (5, 0.9738072829054154)],\n\u001b[92mINFO \u001b[0m:      \t 'recall': [(0, 0.32591540404040403),\n\u001b[92mINFO \u001b[0m:      \t            (1, 0.968864436963376),\n\u001b[92mINFO \u001b[0m:      \t            (2, 0.9717278781885431),\n\u001b[92mINFO \u001b[0m:      \t            (3, 0.9732340020867024),\n\u001b[92mINFO \u001b[0m:      \t            (4, 0.9705149008667157),\n\u001b[92mINFO \u001b[0m:      \t            (5, 0.9719091894956504)]}\n\u001b[92mINFO \u001b[0m:      \n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"History (loss, distributed):\n\tround 1: 0.07006687837100392\n\tround 2: 0.06411206122838563\n\tround 3: 0.06221993791814982\n\tround 4: 0.06240453636389331\n\tround 5: 0.06114359529982764\nHistory (loss, centralized):\n\tround 0: 1.1445508008669938\n\tround 1: 0.07006349834901104\n\tround 2: 0.06411021255557037\n\tround 3: 0.06221808410385321\n\tround 4: 0.06240133009181528\n\tround 5: 0.06114064356780603\nHistory (metrics, centralized):\n{'accuracy': [(0, 0.2288378425443665),\n              (1, 0.9750977567400699),\n              (2, 0.9766650307913942),\n              (3, 0.9774565833425681),\n              (4, 0.9771874554751689),\n              (5, 0.9778206975161081)],\n 'f1': [(0, 0.1304082033134367),\n        (1, 0.9693834500315214),\n        (2, 0.9713599021259088),\n        (3, 0.9724173080414739),\n        (4, 0.9721113667862964),\n        (5, 0.9728450752164716)],\n 'precision': [(0, 0.08289723412713954),\n               (1, 0.9702099596306857),\n               (2, 0.9710032293758516),\n               (3, 0.9716140816221941),\n               (4, 0.9737520527936688),\n               (5, 0.9738072829054154)],\n 'recall': [(0, 0.32591540404040403),\n            (1, 0.968864436963376),\n            (2, 0.9717278781885431),\n            (3, 0.9732340020867024),\n            (4, 0.9705149008667157),\n            (5, 0.9719091894956504)]}"},"metadata":{}},{"name":"stdout","text":"\u001b[36m(ClientAppActor pid=1865)\u001b[0m Client 21055 Evaluation - Loss: 0.0635, Accuracy: 0.9769, Precision: 0.9724, Recall: 0.9709, F1: 0.9716\n","output_type":"stream"}],"execution_count":12}]}